defaults:
  - env_vars: env_vars
  - _self_

seed: 42
window_size: 1
goal_window_size: 10
eval_window_size: 1
batch_size: 512
epochs: 300
eval_freq: 10
eval_on_env_freq: 20
num_env_evals: 1
num_final_evals: 1
num_final_eval_per_goal: 1
action_window_size: 3
sequentially_select: false
vqvae_load_dir: "/home/jellyho/Bimanual_Imitation/checkpoints/transport/2024-10-01/15-19-46/pretrain_transport/trained_vqvae.pt"
goal_dim: 0
run_name: "transport"
action_dim: 14

wandb:
  project: "vq-bet-bimanual-policy"
  entity: ${env_vars.wandb_entity}

device: cuda
optim:
  lr: 5.5e-5
  weight_decay: 2e-4
  betas: [0.9, 0.999]

env:
  gym:
    _target_: transport_env.get_robomimic_env
    dataset_dir: ${env_vars.datasets.transport_config}
  act_dim: 14
  obs_dim: 512
  goal_dim: 0

data:
  _target_: dataset.get_transport_train_val
  data_directory: ${env_vars.datasets.transport}
  goal_conditional: future
  window_size: ${window_size}
  future_seq_len: ${goal_window_size}
  min_future_sep: ${action_window_size}
  action_window_size: ${action_window_size}
  vqbet_get_future_action_chunk: true
  only_sample_tail: false
  train_fraction: 0.99
  vqvae: false

save_every: 10
save_path: "${env_vars.save_path}/checkpoints/${run_name}_policy/${now:%Y-%m-%d}/${now:%H-%M-%S}"
load_path: null

model:
  _target_: vq_behavior_transformer.BehaviorTransformer
  obs_dim: ${env.obs_dim}
  act_dim: ${env.act_dim}
  goal_dim: ${env.goal_dim}
  obs_window_size: ${window_size}
  act_window_size: ${action_window_size}
  sequentially_select: ${sequentially_select}
  visual_input: true
  gpt_model:
    _target_: vq_behavior_transformer.GPT
    config:
      _target_: vq_behavior_transformer.GPTConfig
      block_size: 110
      input_dim: 1024
      n_layer: 6
      n_head: 6
      n_embd: 120
  vqvae_model:
    _target_: vqvae.VqVae
    input_dim_h: ${action_window_size}
    input_dim_w: ${action_dim}
    n_latent_dims: 512
    vqvae_n_embed: 32
    vqvae_groups: 2
    eval: true
    device: ${device}
    load_dir: ${vqvae_load_dir}
  offset_loss_multiplier: 0.1
  secondary_code_multiplier: 3

goal_fn:
  _target_: ant_env.get_goal_fn
  data_directory: ${env_vars.datasets.ant}
  goal_conditional: ${data.goal_conditional}
  seed: ${seed}
  train_fraction: 0.95
  goal_seq_len: ${goal_window_size}
  unconditional: true